
kafka on windows(localhost):

	https://www.cnblogs.com/mh-study/p/9537970.html
	
	### create topic:
	kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic jiajinghist
	
	### 查看topic list
	kafka-topics.sh --list --zookeeper localhost:2181
	
	### 删除topic
	kafka-topics.sh --delete --zookeeper localhost:2181 --topic jiajinghist
	
	### Producer
	kafka-console-producer.bat --broker-list localhost:9092 --topic testDemo
	
	
	### Consumer	from-beginning:从开头消费
	kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic jiajinghist
	−−zookeeper 参数标注为 “过时”，推荐使用 −−bootstrap-server 参数
	kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic vehicle
	
	kafka-console-consumer.bat --bootstrap-server localhost:9092 --group kaka --topic kfk4flux
	kafka-console-consumer.bat --zookeeper localhost:2181 --offset earliest --topic transmsg 
	
	kafka-console-consumer.bat --topic box --zookeeper 119.45.192.201:2181
	
	kafka-console-consumer.sh --topic box --bootstrap-server 119.45.192.201:9092
	
	kafka-console-consumer.bat --topic __consumer_offsets -- zookeeper localhost:2181 --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --consumer.config config/consumer.properties --from-beginning --topic transmsg 


	#### start zookeeper
	zkServer
	
	### start kafka
	cd D:\apacheprogram\kafka_2.12-0.11.0.0
	.\bin\windows\kafka-server-start.bat .\config\server.properties


zookeeper启动失败：
	出现这个问题主要是由于8080端口占用，可在zoo.cfg中增加admin.serverPort=没有被占用的端口号解决问题。
	
	admin.serverPort=8081


Kafka on Linux:

	#创建
	kafka-topics --create --zookeeper master:2181,node1:2181,node2:2181 --replication-factor 2 --partitions 3 --topic kfk4flux


	kafka-topics --list --zookeeper master:2181,node1:2181,node2:2181 

	#消费
	kafka-console-consumer --bootstrap-server master:9092 --from-beginning --topic pxkj
	kafka-console-consumer --bootstrap-server master:9092 --topic fakedata
	kafka-console-consumer.sh --bootstrap-server 192.168.0.178:9093 --topic jiajingMonitor
	
	#推送发布
	kafka-console-producer --broker-list master:9092,node1:9092,node2:9092 --topic pxkj


	kafka-producer-perf-test.sh --topic cod --num-records 10000 --throughput 60 --producer-props bootstrap.servers=master:9092 --payload-file ./cod.txt

	kafka-console-consumer --bootstrap-server master:9092 --from-beginning --topic cod

	pip install kafka_python==2.0.1 numpy==1.19.1 matplotlib==2.2.2 pykafka==2.8.0 influxdb_client==1.10.0 kafka==1.3.5 -i https://pypi.tuna.tsinghua.edu.cn/simple
	pip install pyspark==2.4.6 https://pypi.tuna.tsinghua.edu.cn/simple
	
	pip install kafka_python==2.0.1 numpy==1.19.1 matplotlib==2.2.2 pykafka==2.8.0 influxdb_client==1.10.0 kafka==1.3.5 -i https://pypi.tuna.tsinghua.edu.cn/simple
	
	cd /home/pxkj/wzl/spark-demo/pyspark-2.4.6
	
	python setup.py instal
	
	

cd /home/pxkj/wzl/spark-demo/datageneratePK

# 1.提交写往influxdb脚本执行（9个进程）
	spark-submit --master local[3] --driver-memory 5g --num-executors 5 --executor-cores 1 --executor-memory 1G  --conf spark.pyspark.python=/usr/local/python3/bin/python3.6 --conf spark.pyspark.driver.python=/usr/local/python3/bin/python3.6 cloud_kafka2influx.py
	
# 2. 提交spark 消费 kafka 并往另外topic中发布消息的脚本执行（单个进程）
	spark-submit --master local[3] --driver-memory 5g --num-executors 5 --executor-cores 1 --executor-memory 1G  --conf spark.pyspark.python=/usr/local/python3/bin/python3.6 --conf spark.pyspark.driver.python=/usr/local/python3/bin/python3.6 cloud_spark_kafka.py

# 3. 提交执行publish脚本执行（9个进程）
	spark-submit --master local[3] --driver-memory 5g --num-executors 5 --executor-cores 1 --executor-memory 1G  --conf spark.pyspark.python=/usr/local/python3/bin/python3.6 --conf spark.pyspark.driver.python=/usr/local/python3/bin/python3.6 cloud_publishkafka.py


spark-submit --master local[3] --driver-memory 5g --num-executors 5 --executor-cores 1 --executor-memory 1G  --conf spark.pyspark.python=/usr/local/python3/bin/python3.6 /home/pxkj/wzl/sparkstream/streaming.py localhost 18001



使用docker搭建kafka集群：
	https://www.jianshu.com/p/ac03f126980e
	
	列出所有topics (在本地kafka路径下)
	$ docker exec -it kafka1 kafka-topics.sh --list --zookeeper zookeeper1:2181

	列出所有Kafka brokers
	$ docker exec -it hive_zookeeper_1 bin/zkCli.sh ls /brokers/ids
	$ docker exec -it zookeeper bin/zkCli.sh ls /brokers/ids

	
	# 测试脚本
	#!/bin/bash
	docker exec -it kafka1 kafka-topics.sh --zookeeper zookeeper1:2181 --create --topic test --partitions 3 --replication-factor 3
	sleep 3
	docker exec -it kafka1 kafka-topics.sh --list --zookeeper zookeeper1:2181
	sleep 3
	docker exec -it kafka1 kafka-producer-perf-test.sh --topic test --num-records 50000000 --record-size 100 --throughput -1 --producer-props acks=1 bootstrap.servers=kafka1:9092 buffer.memory=67108864 batch.size=8196

	
	# 消费
	docker exec -it kafka1 kafka-console-consumer.sh --bootstrap-server kafka1:9092 --topic test

Kafka的partions和replication-factor参数:
	https://www.cnblogs.com/lgjlife/p/10569187.html

查看topic最后十条数据，返回当前offset(数据量)：
	kafkacat -b localhost:9092 -t jiajinghist -p 0 -o -10 -e
	
	
kafka on linux:
	# 启动zookeeper
	bin/zookeeper-server-start.sh config/zookeeper.properties &
	# 启动kafka
	bin/kafka-server-start.sh ./config/server.properties &
	### 查看topic list
	bin/kafka-topics.sh --list --zookeeper localhost:2182
	# 创建topic
	### create topic:
	kafka-topics.sh --create --zookeeper localhost:2182 --replication-factor 1 --partitions 1 --topic jiajingMonitor
	# 消费
	kafka-console-consumer.sh --bootstrap-server 192.168.2.178:9093 --topic jiajingMonitor
	#推送发布
	kafka-console-producer.sh --broker-list localhost:9093 --topic jiajingMonitor
	
	# 删除topic
	kafka-topics.sh --delete --zookeeper localhost:2182 --topic jiajingMonitor


	私有云上或本地（内网）无法使用kafka问题解决：
	# vim config/server.properties
	listeners=PLAINTEXT://192.168.0.178:9093      # 设置成内网ip，以后通过内网ip访问

	私有云或内网均可连接kafka
	# 启动服务，后台运行
	nohup bin/zookeeper-server-start.sh config/zookeeper.properties >/dev/null 2>&1 &
	nohup bin/kafka-server-start.sh ./config/server.properties >/dev/null 2>&1 &