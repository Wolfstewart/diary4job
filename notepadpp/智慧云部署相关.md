### 智能问答

- 项目地址：/px-ai/QA/qadeploy

- 配置文件：/px-ai/QA/qadeploy/configs/configDB.ini

  ```ini
  [db]
  host=101.37.203.206
  user=root
  password=6zbMNFmCSl7b/UKfB42N4A
  database=aiops_wisdom_knowl
  port=3306
  charset=utf8
  ```

  

- 启动：开放端口为18006，与后端一致。

  ```shell
  python qadeploy_pb.py
  ```

  

- 注意：数据存放在aiops_wisdom_knowl中，切换部署环境要迁移数据

  

### 舆情监控

- 功能说明：文本分类接口

- 项目地址：/px-ai/sentiment

- 启动：端口 8006

  ```shell
  python pb_deploy.py
  ```

- ```
  请求url：/sentiment/predict?text=你好
  ```

- #### 定时打标任务

  - 定时对爬取来的数据打标并保存结果

  - main文件：processSentiment.py

  - 配置文件：configs/mysqlConf.json

    ```json
    {
      "host": "101.37.203.206",
      "user": "root",
      "password": "6zbMNFmCSl7b/UKfB42N4A",
      "database": "aiops_operation_basis",
      "port": 3306,
      "charset": "utf8",
      "currentIdx": 203
    }
    ```

    

  - 启动 - 定时执行：

    ```shell
    python processSentiment.py
    ```

    

  - 

### 智慧巡检

- #### 数据更新，转发kafka

  - 功能说明：消费rabbitMQ中消息，更新redis快照表，转发到kafka

  - 项目地址：/px-ai/inspDispatch

  - 依赖安装：

    ```shell
    pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
    ```

  - main文件位置：inspDispatch/monitor

  - 配置文件：

    - inspDispatch/monitor/config/configMQ.ini，
    - inspDispatch/monitor/config/configRedis.ini
    - inspDispatch/monitor/monitor/config/kafka.ini

  - 启动 - 后台一直运行

    ```shell
    cd monitor
    nohup python from_rabMQ_2_kafka.py >/dev/null 2>&1 &
    ```

    

  - 

- #### 数据落地到hive

  - 功能说明：消费kafka中数据，落地到hive数据仓库中，后台一直运行。

  - 项目地址：/px-ai/spark-jiajing

  - main文件：src/main/scala/JiaJingMonitorToHive.scala

  - 配置文件：JiajingConf/conf.jiajing.history.json

    ```json
    {
      "source": {
        "type": "kafka",
        "host": "192.168.2.178",
        "port": "9093",
        "topic": "jiajingMonitor",
        "startOffset": "latest",
        "groupId": "tohive"
      },
      "sink": {
        "type": "hive",
        "uri": "thrift://localhost:9083",
        "metaPath": "hdfs://192.168.2.178:8020/user/hive/warehouse",
        "name": "jiajing",
        "table": "monitor",
        "saveMode": "append"
      }
    }
    ```

    

  - 启动，后台一直运行，目前运行在私有云大数据：

    ```shell
    sbt package
    spark-submit --class JiaJingMonitorToHive --master local[*] --packages "org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.6,org.apache.kafka:kafka-clients:1.1.0,org.apache.spark:spark-hive_2.11:2.4.7,org.apache.spark:spark-hive-thriftserver_2.11:2.4.7" target/scala-2.11/simple-project_2.11-1.0.jar /home/zy/wzl/wisdom/spark-jiajing/JiajingConf/conf.jiajing.history.json
    ```

    

  - 

- #### 巡检

  - 功能说明：读取redis中快照表，巡检结果推入rabbitMQ中。

  - 项目：/px-ai/spark-jiajing

  - 类文件：src/main/scala/Insp.scala

  - 配置文件：JiajingConf/insp.json

    ```json
    {
      "redis": {
        "host": "192.168.2.178",
        "port": "6379"
      },
      "mysql": {
        "url": "jdbc:mysql://192.168.2.178:3306",
        "user": "root",
        "password": "6zbMNFmCSl7b/UKfB42N4A"
      }
    }
    ```

    

  - 启动-定时任务：

    ```shell
    spark-submit --class Insp --master local[*] --packages "com.redislabs:spark-redis_2.11:2.4.2,org.mongodb.spark:mongo-spark-connector_2.11:2.4.2,com.rabbitmq:amqp-client:4.11.0" target/scala-2.11/simple-project_2.11-1.0.jar  /home/zy/wzl/wisdom/spark-jiajing/JiajingConfig/insp.json
    ```

    或者：

    ```shell
    sh /home/zy/wzl/wisdom/spark-jiajing/insp.sh
    ```

- #### 累计流量保存

  - 功能说明：读取redis中快照表，累计流量写入mysql

  - 项目：/px-ai/spark-jiajing

  - 类文件：src/main/scala/CumFlow.scala

  - 配置文件：JiajingConf/cumflow.json

    ```json
    {
      "redis": {
        "host": "192.168.2.178",
        "port": "6379"
      },
      "mysql": {
        "url": "jdbc:mysql://192.168.2.178:3306",
        "user": "root",
        "password": "6zbMNFmCSl7b/UKfB42N4A",
        "dbName": "aiops_wisdom_insp",
        "table": "cumflow"
      }
    }
    ```

    

  - 启动：

    ```shell
    spark-submit --class CumFlow --master local[*] --packages "com.redislabs:spark-redis_2.11:2.4.2,org.mongodb.spark:mongo-spark-connector_2.11:2.4.2,com.rabbitmq:amqp-client:4.11.0" target/scala-2.11/simple-project_2.11-1.0.jar  /home/zy/wzl/wisdom/spark-jiajing/JiajingConfig/cumflow.json
    ```

    

- #### 巡检结果处理

  - 功能说明：消费并过虑队列中告警信息，扔进下一级队列生成工单。

  - 项目地址：/px-ai/inspDispatch

  - main文件：inspQueue/faultHandle.py

  - 配置文件：

    - inspQueue/conf/configMQ.ini
    - inspQueue/conf/mysqlConf.json

  - 启动 - 后台运行：

    ```shell
    cd inspQueue
    nohup python faultHandle.py >/dev/null 2>&1 &
    ```

    

  - 

  

### 智能派单

- 功能说明：消费待派单队列，指定维修人员，扔进下一级队列进行工单流程。

- 项目地址：/px-ai/inspDispatch

- main文件：dispatch/dispatch_worker.py

- 配置文件：

  - dispatch/config/configDB.ini
  - dispatch/config/configMQ.ini

- 启动 - 后台运行：

  ```shell
  cd dispatch
  nohup python dispatch_worker.py >/dev/null 2>&1 &
  ```

  



### 运维相关

- 站点密度计算

  - 项目位置：/px-ai/siteDensity

  - 主文件：flask_coor.py

  - 启动 - 后台运行：

    ```shell
    nohup python flask_coor.py >/dev/null 2>&1 &
    ```

  

- 车辆位置

  项目：https://github.com/tianna1121/vehicle



### 其他注意事项

- RabbitMQ服务挂掉之后需要手动创建两个队列

  - RabbitMq to kafka

    ```ini
    [info]
    exchange = mqttExchange
    queue = BoxMonitorValueToKafka
    routing_key = exchange.box.dMonUpdateValueProto
    ```

  - 告警接收队列

    ```ini
    [info]
    exchange = pub.mq.create.repairs.exchange
    queue = pub.mq.create.repairs.fault.queue
    routing_key = pub.mq.create.repairs.fault.queue.routing.key
    ```

    