hadoop 2.7
https://blog.csdn.net/beishanyingluo/article/details/101938568

yarn 
spark 3.0.1

kafka:
	https://blog.csdn.net/qq_34972876/article/details/108160372



{

  "driverClassName": "com.gbase.jdbc.Driver",
  "url": "jdbc:gbase://101.37.203.206:5258",
  "username": "root"
}

{

  "driverClassName": "dm.jdbc.driver.DmDriver",
  "url": "jdbc:dm://101.37.203.206:5236/SYSDBA?zeroDateTimeBehavior=convertToNull&useUnicode=true&characterEncoding=utf-8",
  "username": "SYSDBA",
"password":"SYSDBA"
}


hive安装配置：
	
hdfs读取：
	https://arrow.apache.org/docs/python/
	
基于Docker处理大数据:
	https://www.cnblogs.com/hzcya1995/p/13290401.html

	
Hadoop 2.x常用端口及查看方法：
	https://blog.51cto.com/tenderness/1942791
	
	

Zeppelin：https://www.jianshu.com/p/9b4b84624943
	Apache Zeppelin是一款基于Web的NoteBook，支持交互式数据分析。使用Zeppelin，可以使用丰富的预构建语言后端（或解释器）制作精美的数据驱动，交互式和协作文档，例如Scala（使用Apache Spark），Python（使用Apache Spark），SparkSQL，Hive ，Markdown，Angular和Shell。


streamSets:https://zhuanlan.zhihu.com/p/83314252?from_voters_page=true
	Streamsets是一款大数据实时采集和ETL工具，可以实现不写一行代码完成数据的采集和流转。通过拖拽式的可视化界面，实现数据管道(Pipelines)的设计和定时任务调度。最大的特点有：
	- 可视化界面操作，不写代码完成数据的采集和流转
	- 内置监控，可是实时查看数据流传输的基本信息和数据的质量
	- 强大的整合力，对现有常用组件全力支持，包括50种数据源、44种数据操作、46种目的地。

	对于Streamsets来说，最重要的概念就是数据源(Origins)、操作(Processors)、目的地(Destinations)。创建一个Pipelines管道配置也基本是这三个方面。

	常见的Origins有Kafka、HTTP、UDP、JDBC、HDFS等；Processors可以实现对每个字段的过滤、更改、编码、聚合等操作；Destinations跟Origins差不多，可以写入Kafka、Flume、JDBC、HDFS、Redis等。
	


GaussDB(openGauss):
	下载：
		https://opengauss.org/en/docs/1.0.1/docs/installation/installing-the-opengauss.html
	教程：
		https://www.bookstack.cn/read/opengauss-1.0-zh/c58da3c1406ed331.md
		https://gitee.com/zhongjun2/docs/tree/master/content/zh/docs/Quickstart


hadoop:
	重新格式化：https://www.jb51.net/article/126010.htm
	